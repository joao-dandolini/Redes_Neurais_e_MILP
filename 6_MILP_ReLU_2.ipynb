{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c40515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloco 0: Importações ---\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib       # Para carregar os scalers\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cf29005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definição da classe 'Net' concluída.\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco 1: Definição da Arquitetura da Rede (NECESSÁRIO) ---\n",
    "#\n",
    "# Precisamos re-definir a MESMA classe 'Net' que usamos no treinamento\n",
    "# para que o PyTorch possa carregar os pesos salvos nela.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, n_layers, n_neurons):\n",
    "        super(Net, self).__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(1, n_neurons))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(nn.Linear(n_neurons, n_neurons))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(n_neurons, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"Definição da classe 'Net' concluída.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a22d667c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando Artefatos de Treinamento ---\n",
      "Modelo 'zzzzz_final.pth' carregado.\n",
      "Pesos e vieses de 2 camadas extraídos.\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco 2: Carregar Modelo, Scalers e Extrair Pesos ---\n",
    "\n",
    "print(\"--- Carregando Artefatos de Treinamento ---\")\n",
    "# 1. Carregar os Scalers\n",
    "try:\n",
    "    x_scaler = joblib.load('x_scaler.joblib')\n",
    "    y_scaler = joblib.load('y_scaler.joblib')\n",
    "except FileNotFoundError:\n",
    "    print(\"ERRO: Arquivos 'x_scaler.joblib' ou 'y_scaler.joblib' não encontrados.\")\n",
    "    print(\"Por favor, rode o notebook 'treinamento_redes.ipynb' primeiro.\")\n",
    "    # (Parar a execução do notebook aqui)\n",
    "\n",
    "# 2. Re-instanciar a arquitetura EXATA que foi salva\n",
    "# (Do nosso notebook de transfer-learning)\n",
    "#'''\n",
    "ARCH_N_LAYERS = 1\n",
    "ARCH_N_NEURONS = 37\n",
    "MODEL_PATH = 'zzzzz_final.pth'\n",
    "#'''\n",
    "'''\n",
    "ARCH_N_LAYERS = 2\n",
    "ARCH_N_NEURONS = 13\n",
    "MODEL_PATH = 'transfer_model_final_limited.pth'\n",
    "#'''\n",
    "'''\n",
    "ARCH_N_LAYERS = 3\n",
    "ARCH_N_NEURONS = 20\n",
    "MODEL_PATH = 'transfer_model_final_best.pth'\n",
    "#'''\n",
    "# 3. Instanciar o modelo e carregar os pesos\n",
    "trained_model = Net(n_layers=ARCH_N_LAYERS, n_neurons=ARCH_N_NEURONS)\n",
    "try:\n",
    "    trained_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Modelo '{MODEL_PATH}' não encontrado.\")\n",
    "    # (Parar a execução do notebook aqui)\n",
    "    \n",
    "trained_model.eval() # Colocar em modo de avaliação\n",
    "print(f\"Modelo '{MODEL_PATH}' carregado.\")\n",
    "\n",
    "# 4. Extrair Pesos (Weights) e Vieses (Biases)\n",
    "# Vamos salvá-los em um formato que o Gurobi possa ler (NumPy)\n",
    "nn_params = {}\n",
    "layer_count = 0\n",
    "for name, param in trained_model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        nn_params[f'W{layer_count}'] = param.data.cpu().numpy()\n",
    "    elif 'bias' in name:\n",
    "        nn_params[f'b{layer_count}'] = param.data.cpu().numpy()\n",
    "        layer_count += 1\n",
    "\n",
    "print(f\"Pesos e vieses de {layer_count} camadas extraídos.\")\n",
    "# nn_params agora se parece com:\n",
    "# {'W0': array, 'b0': array, 'W1': array, 'b1': array, 'W2': array, 'b2': array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c55ec971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função 'calculate_layer_bounds' definida.\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco 3: Função de Cálculo de Bounds (Bound Tightening) ---\n",
    "#\n",
    "# Esta é a parte mais crítica da formulação MILP-ReLU.\n",
    "# Precisamos saber os limites (Mínimo L, Máximo U) da *entrada*\n",
    "# de cada neurônio (W*x + b) para criar as restrições \"Big-M\".\n",
    "#\n",
    "# Usaremos \"Aritmética Intervalar\".\n",
    "\n",
    "def calculate_layer_bounds(input_bounds_list, W, b):\n",
    "    \"\"\"\n",
    "    Calcula os bounds de pré-ativação (Wx+b) para uma camada.\n",
    "    \n",
    "    :param input_bounds_list: Lista de tuplas [(L1, U1), (L2, U2), ...] \n",
    "                              dos *inputs* desta camada.\n",
    "    :param W: Matriz de pesos (NumPy) da camada.\n",
    "    :param b: Vetor de vieses (NumPy) da camada.\n",
    "    :return: Lista de tuplas [(L_out1, U_out1), ...] dos bounds de \n",
    "             *pré-ativação* (antes do ReLU).\n",
    "    \"\"\"\n",
    "    \n",
    "    n_neurons_out = W.shape[0]\n",
    "    n_neurons_in = W.shape[1]\n",
    "    \n",
    "    # Criar vetores L e U dos inputs\n",
    "    L_in = np.array([b[0] for b in input_bounds_list])\n",
    "    U_in = np.array([b[1] for b in input_bounds_list])\n",
    "\n",
    "    # Separar pesos em positivos e negativos\n",
    "    W_pos = np.maximum(W, 0)\n",
    "    W_neg = np.minimum(W, 0)\n",
    "\n",
    "    # Calcular L e U para cada neurônio de saída\n",
    "    # L_out = W_pos * L_in + W_neg * U_in + b\n",
    "    # U_out = W_pos * U_in + W_neg * L_in + b\n",
    "    \n",
    "    L_out = W_pos @ L_in + W_neg @ U_in + b\n",
    "    U_out = W_pos @ U_in + W_neg @ L_in + b\n",
    "\n",
    "    return list(zip(L_out, U_out))\n",
    "\n",
    "print(\"Função 'calculate_layer_bounds' definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e7f78f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Calculando Bounds (Big-M) para todos os neurônios ---\n",
      "Bounds do Input Escalado da Rede (L0): [0.001, 1.178]\n",
      "Bounds calculados para Camada ReLU 1.\n",
      "Bounds Finais (Custo Escalado): [-0.018, 1.245]\n",
      "\n",
      "Bounds REAIS do Custo (C_L, C_U): [-331.72, 22411.78]\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco 4: Pré-Cálculo de TODOS os Bounds da Rede ---\n",
    "\n",
    "print(\"--- Calculando Bounds (Big-M) para todos os neurônios ---\")\n",
    "\n",
    "# 1. Definir os bounds de entrada da rede\n",
    "# A rede foi treinada no domínio [30, 200]\n",
    "# O scaler transforma [30, 200] para [0, 1]\n",
    "# O input para o *modelo Gurobi* P_carvao,t é [0, 200]\n",
    "# (P=0 quando z=0)\n",
    "\n",
    "# O que acontece com P=0 (quando z=0)?\n",
    "# P_scaled = (0 - x_scaler.min_[0]) * x_scaler.scale_[0]\n",
    "# P_scaled = (0 - 30) / (200 - 30) * 1 = -30 / 170 = -0.176\n",
    "#\n",
    "# O que acontece com P=30 (mínimo, z=1)?\n",
    "# P_scaled = (30 - 30) * ... = 0\n",
    "#\n",
    "# O que acontece com P=200 (máximo, z=1)?\n",
    "# P_scaled = (200 - 30) * ... = 1\n",
    "\n",
    "# Portanto, o input *escalado* que a rede verá está na faixa [-0.176, 1.0]\n",
    "input_L = (0 - x_scaler.min_[0]) * x_scaler.scale_[0]\n",
    "input_U = (200 - x_scaler.min_[0]) * x_scaler.scale_[0]\n",
    "\n",
    "# Bounds da Camada 0 (Input da Rede)\n",
    "# Lista de tuplas (L, U)\n",
    "current_bounds = [(input_L, input_U)] \n",
    "print(f\"Bounds do Input Escalado da Rede (L0): [{input_L:.3f}, {input_U:.3f}]\")\n",
    "\n",
    "# Guardar os bounds de todas as camadas\n",
    "all_bounds = {}\n",
    "\n",
    "# 2. Calcular bounds para as camadas ReLU\n",
    "n_relu_layers = ARCH_N_LAYERS\n",
    "for i in range(n_relu_layers):\n",
    "    W = nn_params[f'W{i}']\n",
    "    b = nn_params[f'b{i}']\n",
    "    \n",
    "    # Calcular bounds de pré-ativação (Wx+b)\n",
    "    pre_act_bounds = calculate_layer_bounds(current_bounds, W, b)\n",
    "    all_bounds[f'L{i+1}_pre'] = pre_act_bounds\n",
    "    \n",
    "    # Calcular bounds de pós-ativação (ReLU)\n",
    "    # L_post = max(0, L_pre), U_post = max(0, U_pre)\n",
    "    post_act_bounds = [(max(0, L), max(0, U)) for L, U in pre_act_bounds]\n",
    "    all_bounds[f'L{i+1}_post'] = post_act_bounds\n",
    "    \n",
    "    # A saída desta camada é a entrada da próxima\n",
    "    current_bounds = post_act_bounds\n",
    "    \n",
    "    print(f\"Bounds calculados para Camada ReLU {i+1}.\")\n",
    "\n",
    "# 3. Bounds da Camada Final (Linear)\n",
    "# A camada final não tem ReLU\n",
    "W_final = nn_params[f'W{n_relu_layers}']\n",
    "b_final = nn_params[f'b{n_relu_layers}']\n",
    "final_bounds = calculate_layer_bounds(current_bounds, W_final, b_final)\n",
    "all_bounds['Final_Output_Scaled'] = final_bounds\n",
    "\n",
    "print(f\"Bounds Finais (Custo Escalado): [{final_bounds[0][0]:.3f}, {final_bounds[0][1]:.3f}]\\n\")\n",
    "\n",
    "# --- INÍCIO DA MODIFICAÇÃO (ADIÇÃO) ---\n",
    "# Precisamos dos bounds REAIS (des-escalados) do custo para a linearização\n",
    "y_min_scaled, y_max_scaled = final_bounds[0]\n",
    "\n",
    "# C_L = Custo Mínimo Real (pode ser negativo se a NN extrapolar mal)\n",
    "# C_U = Custo Máximo Real\n",
    "C_L_real = (y_min_scaled / y_scaler.scale_[0]) + y_scaler.min_[0]\n",
    "C_U_real = (y_max_scaled / y_scaler.scale_[0]) + y_scaler.min_[0]\n",
    "\n",
    "print(f\"Bounds REAIS do Custo (C_L, C_U): [{C_L_real:.2f}, {C_U_real:.2f}]\")\n",
    "# --- FIM DA MODIFICAÇÃO ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae86343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bloco 5: Carregar Dados do Problema (Gurobi) ---\n",
    "# IDÊNTICO aos notebooks anteriores.\n",
    "\n",
    "# 48 períodos de 30 minutos\n",
    "T = range(1, 49)\n",
    "\n",
    "# Demanda por período (MW)\n",
    "D_lista = [\n",
    "    90, 98, 95, 93, 90, 90, 92, 95, 100, 105, 110, 120, 130, 140, 150, 165, \n",
    "    180, 195, 210, 225, 240, 245, 250, 248, 245, 240, 230, 225, 220, 215, \n",
    "    210, 205, 200, 195, 190, 200, 210, 220, 230, 240, 235, 230, 215, 200, \n",
    "    175, 150, 130, 115\n",
    "]\n",
    "D = {t: D_lista[t-1] for t in T}\n",
    "\n",
    "# --- Usina a Gás (Linear) ---\n",
    "gas_params = {\n",
    "    'var_cost': 80,    # R$/MW\n",
    "    'fix_cost': 250,   # R$/período\n",
    "    'max_cap': 150,    # MW\n",
    "    'min_gen': 45,     # MW\n",
    "    'ramp_rate': 50,   # MW/30min\n",
    "    'min_uptime': 3    # períodos\n",
    "}\n",
    "\n",
    "# --- Usina a Carvão (Não-Linear) ---\n",
    "carvao_params = {\n",
    "    # Custo Variável: 60*P + 0.2*P^2\n",
    "    'fix_cost': 1000,         # R$/período\n",
    "    'max_cap': 200,           # MW\n",
    "    'min_gen': 30,            # MW\n",
    "    'ramp_rate': 40,          # MW/30min\n",
    "    'min_uptime': 1           # períodos\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91e67940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Presolve to value 0\n"
     ]
    }
   ],
   "source": [
    "# --- Bloco 6: Criação do Modelo Gurobi (MILP-ReLU) ---\n",
    "\n",
    "m = gp.Model(\"MILP_Despacho_ReLU\")\n",
    "\n",
    "# Desativar o Presolve (como solicitado)\n",
    "m.setParam('Presolve', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "356d64b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis do Gurobi (incluindo as da rede) criadas.\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Definição das Variáveis de Decisão ---\n",
    "\n",
    "# --- Variáveis Originais ---\n",
    "T_with_0 = range(0, 49) \n",
    "P_gas = m.addVars(T_with_0, name=\"P_gas\", lb=0.0)\n",
    "P_carvao = m.addVars(T_with_0, name=\"P_carvao\", lb=0.0)\n",
    "z_gas = m.addVars(T_with_0, name=\"z_gas\", vtype=GRB.BINARY)\n",
    "z_carvao = m.addVars(T_with_0, name=\"z_carvao\", vtype=GRB.BINARY)\n",
    "start_gas = m.addVars(T, name=\"start_gas\", vtype=GRB.BINARY)\n",
    "start_carvao = m.addVars(T, name=\"start_carvao\", vtype=GRB.BINARY)\n",
    "\n",
    "# --- Novas Variáveis para a Rede Neural (para cada período t) ---\n",
    "\n",
    "# --- INÍCIO DA MODIFICAÇÃO ---\n",
    "\n",
    "# C_var_carvao_hat: O custo variável REAL (desnormalizado) que vai para o OBJETIVO.\n",
    "# Note o lb=0.0 (custo variável não pode ser negativo)\n",
    "C_var_carvao_hat = m.addVars(\n",
    "    T, name=\"C_var_carvao_hat\", lb=0.0, ub=max(0, C_U_real)\n",
    ")\n",
    "\n",
    "# C_nn_descaled: Variável INTERMEDIÁRIA que recebe a saída da NN.\n",
    "# Ela pode ser negativa se a NN extrapolar mal.\n",
    "C_nn_descaled = m.addVars(\n",
    "    T, name=\"C_nn_descaled\", lb=C_L_real, ub=C_U_real\n",
    ")\n",
    "\n",
    "# --- FIM DA MODIFICAÇÃO ---\n",
    "\n",
    "\n",
    "# Variáveis internas da rede (por período t, por camada l, por neurônio j)\n",
    "\n",
    "# --- CORREÇÃO AQUI ---\n",
    "# A variável correta é 'input_U' (com underscore)\n",
    "nn_input_scaled = m.addVars(T, name=\"nn_in_scaled\", lb=input_L, ub=input_U)\n",
    "# --- FIM DA CORREÇÃO ---\n",
    "\n",
    "nn_layer_output = {} # Saída PÓS-ReLU\n",
    "nn_neuron_binary = {} # Variável 'z' do Big-M\n",
    "\n",
    "# Criar variáveis para as camadas ReLU\n",
    "for t in T:\n",
    "    for l in range(n_relu_layers): # Camadas 0 e 1 (que são L1 e L2)\n",
    "        n_neurons = nn_params[f'W{l}'].shape[0]\n",
    "        # Pegar os bounds pós-ativação\n",
    "        post_bounds = all_bounds[f'L{l+1}_post']\n",
    "        \n",
    "        for j in range(n_neurons):\n",
    "            L, U = post_bounds[j]\n",
    "            nn_layer_output[t, l, j] = m.addVar(\n",
    "                name=f\"y_l{l}_n{j}_t{t}\", lb=L, ub=U\n",
    "            )\n",
    "            nn_neuron_binary[t, l, j] = m.addVar(\n",
    "                name=f\"z_l{l}_n{j}_t{t}\", vtype=GRB.BINARY\n",
    "            )\n",
    "\n",
    "print(\"Variáveis do Gurobi (incluindo as da rede) criadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d08b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. Definição da Função Objetivo (LINEAR) ---\n",
    "\n",
    "custo_gas = gp.quicksum(\n",
    "    gas_params['var_cost'] * P_gas[t] + gas_params['fix_cost'] * z_gas[t]\n",
    "    for t in T\n",
    ")\n",
    "\n",
    "# Substituímos a fórmula quadrática pela nossa variável de custo da rede\n",
    "custo_carvao_relu = gp.quicksum(\n",
    "    C_var_carvao_hat[t] + carvao_params['fix_cost'] * z_carvao[t]\n",
    "    for t in T\n",
    ")\n",
    "\n",
    "m.setObjective(custo_gas + custo_carvao_relu, GRB.MINIMIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "412066dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adicionando restrições...\n",
      "Todas as restrições (incluindo Big-M) foram adicionadas.\n"
     ]
    }
   ],
   "source": [
    "# --- 9. Definição das Restrições ---\n",
    "\n",
    "print(\"Adicionando restrições...\")\n",
    "\n",
    "# --- Restrições Originais (Copiadas) ---\n",
    "# Estado Inicial (t=0)\n",
    "m.addConstr(P_gas[0] == 0)\n",
    "m.addConstr(z_gas[0] == 0)\n",
    "m.addConstr(P_carvao[0] == 0)\n",
    "m.addConstr(z_carvao[0] == 0)\n",
    "\n",
    "# Restrições para cada período t = 1 a 48\n",
    "for t in T:\n",
    "    # 1. Atender Demanda\n",
    "    m.addConstr(P_gas[t] + P_carvao[t] >= D[t], name=f\"Demanda_t{t}\")\n",
    "    # 2. Gás\n",
    "    m.addConstr(P_gas[t] <= gas_params['max_cap'] * z_gas[t], name=f\"Gas_MaxCap_t{t}\")\n",
    "    m.addConstr(P_gas[t] >= gas_params['min_gen'] * z_gas[t], name=f\"Gas_MinGen_t{t}\")\n",
    "    # 3. Carvão\n",
    "    m.addConstr(P_carvao[t] <= carvao_params['max_cap'] * z_carvao[t], name=f\"Carvao_MaxCap_t{t}\")\n",
    "    m.addConstr(P_carvao[t] >= carvao_params['min_gen'] * z_carvao[t], name=f\"Carvao_MinGen_t{t}\")\n",
    "    # 4. Rampas\n",
    "    m.addConstr(P_gas[t] - P_gas[t-1] <= gas_params['ramp_rate'], name=f\"Gas_RampUp_t{t}\")\n",
    "    m.addConstr(P_gas[t-1] - P_gas[t] <= gas_params['ramp_rate'], name=f\"Gas_RampDown_t{t}\")\n",
    "    m.addConstr(P_carvao[t] - P_carvao[t-1] <= carvao_params['ramp_rate'], name=f\"Carvao_RampUp_t{t}\")\n",
    "    m.addConstr(P_carvao[t-1] - P_carvao[t] <= carvao_params['ramp_rate'], name=f\"Carvao_RampDown_t{t}\")\n",
    "    # 5. Partida\n",
    "    m.addConstr(start_gas[t] >= z_gas[t] - z_gas[t-1], name=f\"Gas_StartDef_t{t}\")\n",
    "    m.addConstr(start_carvao[t] >= z_carvao[t] - z_carvao[t-1], name=f\"Carvao_StartDef_t{t}\")\n",
    "    # 6. Min Uptime\n",
    "    k_gas = gas_params['min_uptime']\n",
    "    for tau in range(t, min(t + k_gas, 49)): m.addConstr(z_gas[tau] >= start_gas[t])\n",
    "    k_carvao = carvao_params['min_uptime']\n",
    "    for tau in range(t, min(t + k_carvao, 49)): m.addConstr(z_carvao[tau] >= start_carvao[t])\n",
    "\n",
    "    # --- NOVAS Restrições da Rede Neural (para cada t) ---\n",
    "    \n",
    "    # 7. Ligar P_carvao,t (Real) com o Input Escalado da Rede\n",
    "    #    x_scaled = (x_real - x_min) * x_scale\n",
    "    m.addConstr(\n",
    "        nn_input_scaled[t] == (P_carvao[t] - x_scaler.min_[0]) * x_scaler.scale_[0],\n",
    "        name=f\"NN_Input_Scale_t{t}\"\n",
    "    )\n",
    "    \n",
    "    # 8. Restrições \"Big-M\" para as camadas ReLU\n",
    "    current_layer_input_vars = [nn_input_scaled[t]] # Começa com o input\n",
    "    \n",
    "    for l in range(n_relu_layers): # Camadas 0 e 1 (que são L1 e L2)\n",
    "        W = nn_params[f'W{l}']\n",
    "        b = nn_params[f'b{l}']\n",
    "        n_neurons_out = W.shape[0]\n",
    "        n_neurons_in = W.shape[1]\n",
    "        \n",
    "        # Pegar os bounds pré-calculados\n",
    "        pre_act_bounds = all_bounds[f'L{l+1}_pre']\n",
    "        \n",
    "        # Coletar as variáveis de saída desta camada\n",
    "        output_vars_list = [nn_layer_output[t, l, j] for j in range(n_neurons_out)]\n",
    "        \n",
    "        for j in range(n_neurons_out): # Para cada neurônio na camada\n",
    "            \n",
    "            # 1. Definir a pré-ativação (Wx+b)\n",
    "            pre_act = gp.quicksum(\n",
    "                W[j, k] * current_layer_input_vars[k] for k in range(n_neurons_in)\n",
    "            ) + b[j]\n",
    "            \n",
    "            # 2. Pegar as variáveis\n",
    "            y_out = nn_layer_output[t, l, j]\n",
    "            z_bin = nn_neuron_binary[t, l, j]\n",
    "            \n",
    "            # 3. Pegar os bounds L e U (Big-M)\n",
    "            L, U = pre_act_bounds[j]\n",
    "            \n",
    "            # 4. Adicionar as restrições Big-M\n",
    "            # y_out >= Wx+b\n",
    "            m.addConstr(y_out >= pre_act, name=f\"BigM_1_l{l}_n{j}_t{t}\")\n",
    "            # y_out <= (Wx+b) - L*(1-z)\n",
    "            m.addConstr(y_out <= pre_act - L * (1 - z_bin), name=f\"BigM_2_l{l}_n{j}_t{t}\")\n",
    "            # y_out <= U*z\n",
    "            m.addConstr(y_out <= U * z_bin, name=f\"BigM_3_l{l}_n{j}_t{t}\")\n",
    "            # y_out >= 0 (Já garantido pelo lb=0 da var, mas bom ser explícito)\n",
    "            # m.addConstr(y_out >= 0, name=f\"BigM_4_l{l}_n{j}_t{t}\")\n",
    "            \n",
    "        # O input da próxima camada é a saída desta\n",
    "        current_layer_input_vars = output_vars_list\n",
    "    \n",
    "    # 9. Ligar a Camada Final (Linear) à Saída Escalada\n",
    "    # (current_layer_input_vars agora contém as saídas da última camada ReLU)\n",
    "    W_final = nn_params[f'W{n_relu_layers}']\n",
    "    b_final = nn_params[f'b{n_relu_layers}']\n",
    "    \n",
    "    scaled_output_cost = gp.quicksum(\n",
    "        W_final[0, k] * current_layer_input_vars[k] for k in range(ARCH_N_NEURONS)\n",
    "    ) + b_final[0]\n",
    "    \n",
    "    # --- INÍCIO DA MODIFICAÇÃO (LÓGICA INTELIGENTE) ---\n",
    "    \n",
    "    # 10. Des-normalizar a Saída para a variável INTERMEDIÁRIA\n",
    "    # C_real = C_scaled / C_scale + C_min\n",
    "    m.addConstr(\n",
    "        C_nn_descaled[t] == (scaled_output_cost / y_scaler.scale_[0]) + y_scaler.min_[0],\n",
    "        name=f\"NN_Output_Scale_t{t}\"\n",
    "    )\n",
    "\n",
    "    # 11. Lógica Inteligente (Linearização de Fortet)\n",
    "    # Substitui a antiga restrição \"Cost_z_link\"\n",
    "    #\n",
    "    # Modela: C_var_carvao_hat[t] = z_carvao[t] * C_nn_descaled[t]\n",
    "    #\n",
    "    z = z_carvao[t]\n",
    "    C_var = C_var_carvao_hat[t] # Var no objetivo (lb=0)\n",
    "    C_nn = C_nn_descaled[t]      # Var da NN (pode ser negativa)\n",
    "    \n",
    "    # Bounds Reais (calculados no Bloco 4)\n",
    "    L = C_L_real \n",
    "    U = C_U_real \n",
    "\n",
    "    # Se z=0 => C_var = 0.\n",
    "    # Se z=1 => C_var = C_nn.\n",
    "    m.addConstr(C_var <= U * z, name=f\"Fortet_1_t{t}\")\n",
    "    m.addConstr(C_var >= L * z, name=f\"Fortet_2_t{t}\")\n",
    "    m.addConstr(C_var <= C_nn - L * (1 - z), name=f\"Fortet_3_t{t}\")\n",
    "    m.addConstr(C_var >= C_nn - U * (1 - z), name=f\"Fortet_4_t{t}\")\n",
    "    \n",
    "    # --- FIM DA MODIFICAÇÃO ---\n",
    "    \n",
    "\n",
    "print(\"Todas as restrições (incluindo Big-M) foram adicionadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "551471b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Otimização do Modelo MILP-ReLU ---\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Non-default parameters:\n",
      "Presolve  0\n",
      "\n",
      "Optimize a model with 6337 rows, 3988 columns and 16366 nonzeros\n",
      "Model fingerprint: 0x86c1ba6e\n",
      "Variable types: 2018 continuous, 1970 integer (1970 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-03, 2e+04]\n",
      "  Objective range  [1e+00, 1e+03]\n",
      "  Bounds range     [1e-03, 2e+04]\n",
      "  RHS range        [2e-06, 2e+04]\n",
      "Variable types: 2016 continuous, 1972 integer (1970 binary)\n",
      "Found heuristic solution: objective 755003.45166\n",
      "\n",
      "Root relaxation: objective 5.818646e+05, 1099 iterations, 0.01 seconds (0.01 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 581864.635    0  165 755003.452 581864.635  22.9%     -    0s\n",
      "     0     0 598608.732    0  157 755003.452 598608.732  20.7%     -    0s\n",
      "     0     0 733671.028    0  239 755003.452 733671.028  2.83%     -    0s\n",
      "H    0     0                    737571.75156 733751.981  0.52%     -    0s\n",
      "     0     0 734497.339    0  112 737571.752 734497.339  0.42%     -    0s\n",
      "     0     0 734546.624    0  121 737571.752 734546.624  0.41%     -    0s\n",
      "     0     0 734547.967    0  121 737571.752 734547.967  0.41%     -    0s\n",
      "     0     0 735483.024    0    8 737571.752 735483.024  0.28%     -    0s\n",
      "*    0     0               0    735500.87787 735500.878  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Learned: 24\n",
      "  Gomory: 50\n",
      "  Lift-and-project: 3\n",
      "  Cover: 222\n",
      "  Implied bound: 381\n",
      "  Clique: 191\n",
      "  MIR: 83\n",
      "  Flow cover: 149\n",
      "  RLT: 133\n",
      "  Relax-and-lift: 91\n",
      "  BQP: 59\n",
      "\n",
      "Explored 1 nodes (2711 simplex iterations) in 0.64 seconds (0.28 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 735501 737572 755003 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 7.355008778723e+05, best bound 7.355008778723e+05, gap 0.0000%\n",
      "--- Otimização Concluída ---\n"
     ]
    }
   ],
   "source": [
    "# --- 10. Otimização do Modelo ---\n",
    "print(\"\\n--- Iniciando Otimização do Modelo MILP-ReLU ---\")\n",
    "start_time = time.time()\n",
    "\n",
    "m.optimize()\n",
    "end_time = time.time()\n",
    "print(\"--- Otimização Concluída ---\")\n",
    "\n",
    "solve_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12d2bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solução Ótima Encontrada!\n",
      "Custo Total (MILP-ReLU): R$ 735500.88\n",
      "Tempo de Solução: 0.6531 segundos\n",
      "----------------------------------------------------------------------\n",
      "Resumo da Operação (Geração em MW):\n",
      "Per. | Demanda | Gás (P)   | Gás (z) | Carvão (P) | Carvão (z) | Total Gen. | Sobra\n",
      "----------------------------------------------------------------------\n",
      "  1 |   90  |    50.00 |   ON    |      40.00 |     ON     |      90.00 |  0.00\n",
      "  2 |   98  |    98.00 |   ON    |       0.00 |    OFF     |      98.00 |  0.00\n",
      "  3 |   95  |    95.00 |   ON    |       0.00 |    OFF     |      95.00 |  0.00\n",
      "  4 |   93  |    93.00 |   ON    |       0.00 |    OFF     |      93.00 |  0.00\n",
      "  5 |   90  |    90.00 |   ON    |       0.00 |    OFF     |      90.00 |  0.00\n",
      "  6 |   90  |    90.00 |   ON    |       0.00 |    OFF     |      90.00 |  0.00\n",
      "  7 |   92  |    92.00 |   ON    |       0.00 |    OFF     |      92.00 |  0.00\n",
      "  8 |   95  |    95.00 |   ON    |       0.00 |    OFF     |      95.00 |  0.00\n",
      "  9 |  100  |   100.00 |   ON    |       0.00 |    OFF     |     100.00 |  0.00\n",
      " 10 |  105  |   105.00 |   ON    |       0.00 |    OFF     |     105.00 |  0.00\n",
      " 11 |  110  |   110.00 |   ON    |       0.00 |    OFF     |     110.00 |  0.00\n",
      " 12 |  120  |   120.00 |   ON    |       0.00 |    OFF     |     120.00 |  0.00\n",
      " 13 |  130  |   130.00 |   ON    |       0.00 |    OFF     |     130.00 |  0.00\n",
      " 14 |  140  |   140.00 |   ON    |       0.00 |    OFF     |     140.00 |  0.00\n",
      " 15 |  150  |   150.00 |   ON    |       0.00 |    OFF     |     150.00 |  0.00\n",
      " 16 |  165  |   135.00 |   ON    |      30.00 |     ON     |     165.00 |  0.00\n",
      " 17 |  180  |   150.00 |   ON    |      30.00 |     ON     |     180.00 |  0.00\n",
      " 18 |  195  |   150.00 |   ON    |      45.00 |     ON     |     195.00 |  0.00\n",
      " 19 |  210  |   150.00 |   ON    |      60.00 |     ON     |     210.00 |  0.00\n",
      " 20 |  225  |   150.00 |   ON    |      75.00 |     ON     |     225.00 |  0.00\n",
      " 21 |  240  |   150.00 |   ON    |      90.00 |     ON     |     240.00 |  0.00\n",
      " 22 |  245  |   150.00 |   ON    |      95.00 |     ON     |     245.00 |  0.00\n",
      " 23 |  250  |   150.00 |   ON    |     100.00 |     ON     |     250.00 |  0.00\n",
      " 24 |  248  |   150.00 |   ON    |      98.00 |     ON     |     248.00 |  0.00\n",
      " 25 |  245  |   150.00 |   ON    |      95.00 |     ON     |     245.00 |  0.00\n",
      " 26 |  240  |   150.00 |   ON    |      90.00 |     ON     |     240.00 |  0.00\n",
      " 27 |  230  |   150.00 |   ON    |      80.00 |     ON     |     230.00 |  0.00\n",
      " 28 |  225  |   150.00 |   ON    |      75.00 |     ON     |     225.00 |  0.00\n",
      " 29 |  220  |   150.00 |   ON    |      70.00 |     ON     |     220.00 |  0.00\n",
      " 30 |  215  |   150.00 |   ON    |      65.00 |     ON     |     215.00 |  0.00\n",
      " 31 |  210  |   150.00 |   ON    |      60.00 |     ON     |     210.00 |  0.00\n",
      " 32 |  205  |   150.00 |   ON    |      55.00 |     ON     |     205.00 |  0.00\n",
      " 33 |  200  |   150.00 |   ON    |      50.00 |     ON     |     200.00 |  0.00\n",
      " 34 |  195  |   150.00 |   ON    |      45.00 |     ON     |     195.00 |  0.00\n",
      " 35 |  190  |   150.00 |   ON    |      40.00 |     ON     |     190.00 |  0.00\n",
      " 36 |  200  |   150.00 |   ON    |      50.00 |     ON     |     200.00 |  0.00\n",
      " 37 |  210  |   150.00 |   ON    |      60.00 |     ON     |     210.00 |  0.00\n",
      " 38 |  220  |   150.00 |   ON    |      70.00 |     ON     |     220.00 |  0.00\n",
      " 39 |  230  |   150.00 |   ON    |      80.00 |     ON     |     230.00 |  0.00\n",
      " 40 |  240  |   150.00 |   ON    |      90.00 |     ON     |     240.00 |  0.00\n",
      " 41 |  235  |   150.00 |   ON    |      85.00 |     ON     |     235.00 |  0.00\n",
      " 42 |  230  |   150.00 |   ON    |      80.00 |     ON     |     230.00 |  0.00\n",
      " 43 |  215  |   150.00 |   ON    |      65.00 |     ON     |     215.00 |  0.00\n",
      " 44 |  200  |   150.00 |   ON    |      50.00 |     ON     |     200.00 |  0.00\n",
      " 45 |  175  |   145.00 |   ON    |      30.00 |     ON     |     175.00 |  0.00\n",
      " 46 |  150  |   150.00 |   ON    |       0.00 |    OFF     |     150.00 |  0.00\n",
      " 47 |  130  |   130.00 |   ON    |       0.00 |    OFF     |     130.00 |  0.00\n",
      " 48 |  115  |   115.00 |   ON    |       0.00 |    OFF     |     115.00 |  0.00\n"
     ]
    }
   ],
   "source": [
    "# --- 11. Exibição dos Resultados ---\n",
    "if m.Status == GRB.OPTIMAL:\n",
    "    print(f\"\\nSolução Ótima Encontrada!\")\n",
    "    print(f\"Custo Total (MILP-ReLU): R$ {m.ObjVal:.2f}\")\n",
    "    print(f\"Tempo de Solução: {solve_time:.4f} segundos\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    print(\"Resumo da Operação (Geração em MW):\")\n",
    "    print(\"Per. | Demanda | Gás (P)   | Gás (z) | Carvão (P) | Carvão (z) | Total Gen. | Sobra\")\n",
    "    print(\"-\" * 70)\n",
    "    for t in T:\n",
    "        gas_gen = P_gas[t].X\n",
    "        gas_z = \"ON\" if z_gas[t].X > 0.5 else \"OFF\"\n",
    "        carvao_gen = P_carvao[t].X\n",
    "        carvao_z = \"ON\" if z_carvao[t].X > 0.5 else \"OFF\"\n",
    "        total_gen = gas_gen + carvao_gen\n",
    "        sobra = total_gen - D[t]\n",
    "        \n",
    "        print(f\" {t:2d} |  {D[t]:3d}  | {gas_gen:8.2f} | {gas_z:^7} | {carvao_gen:10.2f} | {carvao_z:^10} | {total_gen:10.2f} | {sobra:5.2f}\")\n",
    "\n",
    "elif m.Status == GRB.INFEASIBLE:\n",
    "    print(\"\\n--- ERRO: Modelo Inviável ---\")\n",
    "    m.computeIIS()\n",
    "    m.write(\"modelo_conflito.ilp\")\n",
    "    print(\"IIS salvo em 'modelo_conflito.ilp'.\")\n",
    "else:\n",
    "    print(f\"Otimização terminou com status: {m.Status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
